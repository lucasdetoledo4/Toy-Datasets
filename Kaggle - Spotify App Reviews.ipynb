{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify App Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "\n",
    "# Wordcloud\n",
    "from wordcloud import WordCloud, ImageColorGenerator, STOPWORDS\n",
    "from PIL import Image\n",
    "\n",
    "# Text preprocessing\n",
    "from string import punctuation\n",
    "from textblob import TextBlob, Word\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "import contractions\n",
    "import re\n",
    "import unidecode\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "df = pd.read_csv(\"reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clean:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def drop_cols(self, columns_list):\n",
    "        return self.data.drop(columns_list, axis=1)\n",
    "    \n",
    "    def drop_by_value(self, data_column, value):\n",
    "        return self.data[data_column != value]\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping useless columns\n",
    "df = Clean(df)\n",
    "df = df.drop_cols(['Time_submitted', 'Total_thumbsup', 'Reply'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rating values equals 3 (neither positive or negative)\n",
    "df = Clean(df)\n",
    "df = df.drop_by_value(df['Rating'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New classification column by the rating from reviews (1 or 2: Negative, 4 or 5: Positive)\n",
    "df['NPS'] = np.where(df['Rating'] >= 4, 'Positive', 'Negative')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of characters of each Review (line-by-line)\n",
    "df['Review_chrs_num'] = df['Review'].apply(lambda x: len(x))\n",
    "\n",
    "sns.set_theme(font='Times New Roman')\n",
    "df['Review_chrs_num'].hist(bins='auto', range=(0,520), figsize=(12,8), color='#81b71a')\n",
    "plt.ylabel(\"Count\", fontsize=15)\n",
    "plt.xlabel(\"Number of characters\", fontsize=15)\n",
    "plt.title(\"Review characters distribuition\", fontsize=18)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words of each Review (line-by-line)\n",
    "df['Review_words_num'] = df['Review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df['Review_words_num'].hist(bins='auto', range=(0, 110), figsize=(12,8), color='#81b71a')\n",
    "plt.ylabel(\"Count\", fontsize=15)\n",
    "plt.xlabel(\"Number of words\", fontsize=15)\n",
    "plt.title(\"Review words distribuition\", fontsize=18)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 largest Reviews\n",
    "df.sort_values(by='Review_chrs_num', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better visualization of the largest reviews\n",
    "df_copy = df.copy()\n",
    "largest = list(df_copy.sort_values('Review_chrs_num', ascending=False)['Review'])\n",
    "largest[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 shortest Reviews\n",
    "df.sort_values(by='Review_chrs_num', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest = list(df_copy.sort_values('Review_chrs_num', ascending=True)['Review'])\n",
    "smallest[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud\n",
    "text = \" \".join(word for word in df['Review'])\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "spotify_mask = np.array(Image.open('Spotify-logo.jpg')) \n",
    "spotify_colormap = ImageColorGenerator(spotify_mask)\n",
    "\n",
    "# Creating a wordcloud image\n",
    "wc = WordCloud(\n",
    "                mask=spotify_mask,\n",
    "                stopwords=stopwords,\n",
    "                background_color='white'\n",
    "                ).generate(text)\n",
    "\n",
    "# Generated image\n",
    "plt.imshow(wc.recolor(color_func=spotify_colormap), interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of positive and negative Reviews\n",
    "print(df['NPS'].value_counts())\n",
    "\n",
    "df['NPS'].value_counts().plot(kind='bar', figsize=(12,8), color=['#81b71a', '#cc0000'])\n",
    "plt.xlabel(\"NPS\", fontsize=15)\n",
    "plt.ylabel(\"Count\", fontsize=15)\n",
    "plt.title(\"Counting the positive and negative reviews\")\n",
    "plt.subplot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of duplicate data\n",
    "print(f\"Size of dataframe with duplicated data: {df.shape}\")\n",
    "print(f\"Percent of duplicated data: {df.duplicated().mean():.2%}\")\n",
    "\n",
    "df.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe only with Review and NPS\n",
    "df = df[['Review', 'NPS']]\n",
    "df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe into train and test\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['NPS'])\n",
    "del df\n",
    "\n",
    "X_train = df_train['Review']\n",
    "y_train = df_train['NPS']\n",
    "X_val = None\n",
    "y_val = None\n",
    "X_test = df_test['Review']\n",
    "y_test = df_test['NPS']\n",
    "\n",
    "print(f\"Train size: {df_train.shape}\")\n",
    "print(f\"Test size: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_preprocessor(text):\n",
    "    # Removes punctuation\n",
    "    text = ''.join([letter for letter in text if letter not in punctuation])\n",
    "\n",
    "    # Lower the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # Expandes contractions (for abbreviations)\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    # Removes accents\n",
    "    text = unidecode.unidecode(text)\n",
    "\n",
    "    # Removes urls\n",
    "    text = re.sub(r'(http|https|ssh|ftp|www)\\S+', '', text)\n",
    "\n",
    "    # Removes white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Fix typos\n",
    "    text = str(TextBlob(text).correct())\n",
    "\n",
    "    # Lemmitazation\n",
    "    text = ' '.join([Word(w).lemmatize() for w in text.split()])\n",
    "\n",
    "    return text\n",
    "\n",
    "# Caso quisessemos limpar o texto, como ocorre geralmente para NLP (por√©m ficou muito lento rodando o TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectors\n",
    "cv = CountVectorizer()\n",
    "cv.fit(X_train)\n",
    "\n",
    "X_train_vectorized = cv.transform(X_train)\n",
    "X_test_vectorized = cv.transform(X_test)\n",
    "\n",
    "print(f\"Count vector: {cv.get_feature_names_out()}\")\n",
    "print(f\"Count vector size: {cv.get_feature_names_out().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = pd.DataFrame.sparse.from_spmatrix(\n",
    "                                                cv.transform(X_test),\n",
    "                                                columns=cv.get_feature_names_out()\n",
    ")\n",
    "transformed = transformed.loc[:, (transformed != 0).any()] # Drop columns with all 0s\n",
    "transformed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Validation and Hyperparameters selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe = make_pipeline(CountVectorizer(),\n",
    "                     LogisticRegression(max_iter=200, random_state=42))\n",
    "logreg_pipe[1:].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "param_grid = {\"logisticregression__C\": 10**np.arange(-3,3.01,1),\n",
    "              \"logisticregression__penalty\": ['l1','l2','elasticnet','none']}\n",
    "\n",
    "logreg_gs = GridSearchCV(logreg_pipe, param_grid, cv=5, scoring='balanced_accuracy')\n",
    "logreg_gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", logreg_gs.best_params_)\n",
    "pd.DataFrame(data=logreg_gs.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = make_pipeline(CountVectorizer(),\n",
    "                               LogisticRegression(C=0.1, penalty='l2', max_iter=200, random_state=42))\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train balanced accuracy: {balanced_accuracy_score(y_train, logreg_model.predict(X_train)):.2%}\")\n",
    "print(f\"Validation balanced accuracy (5-fold): {logreg_gs.best_score_:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe = make_pipeline(CountVectorizer(),\n",
    "                         SVC(kernel='rbf', max_iter=200, random_state=42))\n",
    "svm_pipe[1:].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'svc__C':     10.0**np.arange(-3, 3.01, 1), \n",
    "              'svc__gamma': 10.0**np.arange(-3, 3.01, 1)}\n",
    "\n",
    "svm_gs = GridSearchCV(svm_pipe, param_grid, cv=5, scoring='balanced_accuracy')\n",
    "svm_gs.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters:\", svm_gs.best_params_)\n",
    "pd.DataFrame(data=svm_gs.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(svm_gs.cv_results_['param_svc__C'], svm_gs.cv_results_['param_svc__gamma'], c=svm_gs.cv_results_['mean_test_score'], cmap='jet');\n",
    "plt.plot(svm_gs.best_params_['svc__C'], svm_gs.best_params_['svc__gamma'], 'ks', mfc='none', markersize=10)\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('gamma')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.colorbar()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = make_pipeline(CountVectorizer(),\n",
    "                          SVC(kernel='rbf', C=10, gamma=0.01, max_iter=200, random_state=42))\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train balanced accuracy: {balanced_accuracy_score(y_train, svm_model.predict(X_train)):.2%}\")\n",
    "print(f\"Validation balanced accuracy (5-fold): {svm_gs.best_score_:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pipe = make_pipeline(CountVectorizer(),\n",
    "                          DecisionTreeClassifier(random_state=42))\n",
    "\n",
    "tree_pipe[1:].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'decisiontreeclassifier__criterion': ['log_loss', 'entropy','gini'],\n",
    "              'decisiontreeclassifier__max_depth': np.arange(5,15),\n",
    "            #  'decisiotreeclassifier__min_samples_split': np.arange(),\n",
    "            #  'decisiontreeclassifier__min_samples_leaf': np.arange(),\n",
    "            #  'decisiontreeclassifier__max_leaf_nodes': np.arange(),\n",
    "            #  'decisiontreeclassfier__max_features': np.arange(),\n",
    "            #  'decisiontreeclassifier__min_impurity_decrease': np.arange(),\n",
    "              'decisiontreeclassifier__ccp_alpha': np.arange(1,5)/1000}\n",
    "\n",
    "tree_gs = GridSearchCV(tree_pipe, param_grid, cv=5, scoring='balanced_accuracy')\n",
    "tree_gs.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters:\", tree_gs.best_params_)\n",
    "pd.DataFrame(data=tree_gs.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = make_pipeline(CountVectorizer(),\n",
    "                           DecisionTreeClassifier(criterion='log_loss',max_depth=14, ccp_alpha=0.001, random_state=42))\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train balanced accuracy: {balanced_accuracy_score(y_train, tree_model.predict(X_train)):.2%}\")\n",
    "print(f\"Validation balanced accuracy (5-fold): {tree_gs.best_score_:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = make_pipeline(CountVectorizer(),\n",
    "                        RandomForestClassifier(random_state=42))\n",
    "\n",
    "rf_pipe[1:].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'randomforestclassifier__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "            #  'randomforestclassifier__n_estimators': np.arange(100,500.01,100),\n",
    "              'randomforestclassifier__max_depth': np.arange(10,15),\n",
    "            #  'randomforestclassifier__max_features': ['auto','sqrt'],\n",
    "            #  'randomforestclassifier__min_samples_leaf': np.arange(),\n",
    "            #  'randomforestclassifier__min_samples_split': np.arange(),\n",
    "            #  'randomforestclassifier__bootstrap': [True, False],\n",
    "              'randomforestclassifier__ccp_alpha': np.arange(1,5)/1000}\n",
    "\n",
    "rf_gs = GridSearchCV(rf_pipe, param_grid, cv=5, scoring='balanced_accuracy')\n",
    "rf_gs.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters:\", rf_gs.best_params_)\n",
    "pd.DataFrame(data=rf_gs.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = make_pipeline(CountVectorizer(),\n",
    "                         RandomForestClassifier(criterion='entropy',max_depth=14, ccp_alpha=0.001, random_state=42))\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train balanced accuracy: {balanced_accuracy_score(y_train, rf_model.predict(X_train)):.2%}\")\n",
    "print(f\"Validation balanced accuracy (5-fold): {rf_gs.best_score_:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipe = make_pipeline(CountVectorizer(),\n",
    "                        GradientBoostingClassifier(random_state=42))\n",
    "gb_pipe[1:].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "param_grid = {\n",
    "            #  'gradientboostingclassifier__max_depth': np.arange(10,15),\n",
    "              'gradientboostingclassifier__learning_rate': [0.01,0.1,1],\n",
    "            #  'gradientboostingclassifier__loss':  ['log_loss', 'exponential'],\n",
    "            #  'gradientboostingclassifier__n_estimators': [100, 200, 300],\n",
    "              'gradientboostingclassifier__criterion': ['friedman_mse', 'mae', 'squared_error'],\n",
    "            #  'gradientboostingclassifier__min_samples_split': np.arange(),\n",
    "            #  'gradientboostingclassifier__min_samples_leaf': np.arange(),\n",
    "            #  'gradientboostingclassifier__min_weight_fraction_leaf': np.arange(),\n",
    "            #  'gradientboostingclassifier__max_features': np.arange(),\n",
    "            #  'gradientboostingclassifier__max_leaf_nodes': np.arange(),\n",
    "            #  'gradientboostingclassifier__min_impurity_decrease': np.arange(),\n",
    "              'gradientboostingclassifier__ccp_alpha': np.arange(1,5)/1000\n",
    "}\n",
    "\n",
    "gb_gs = GridSearchCV(gb_pipe, param_grid, cv=5, scoring='balanced_accuracy')\n",
    "gb_gs.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best params:\", gb_gs.best_params_)\n",
    "pd.DataFrame(data=gb_gs.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = make_pipeline(CountVectorizer(),\n",
    "                         GradientBoostingClassifier(ccp_alpha=0.001, criterion='friedman_mse', learning_rate=0.1, random_state=42))\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train balanced accuracy: {balanced_accuracy_score(y_train, gb_model.predict(X_train)):.2%}\")\n",
    "print(f\"Validation balanced accuracy (5-fold): {gb_gs.best_score_:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modelo escolhido: SVM com kernel rbf\n",
    "\n",
    "**Retreinamento**: Como, para a valida√ß√£o cruzada k-fold, utilizamos refit=True no GridSearch para otimizar os par√¢metros e depois treinamos o modelo com os dados j√° otimizados com o conjunto de treinamento completo, n√£o h√° necessidade de fazer um retreinamento. Sendo assim, continuarei com os pr√≥ximos t√≥picos a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using logistic regression model for the test dataset\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "print(f\"Test balanced accuracy: {balanced_accuracy_score(y_test, y_pred):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix by logistic regression\n",
    "cfn_matrix = confusion_matrix(y_test, logreg_model.predict(X_test))\n",
    "print(f\"Confusion Matrix: \"'\\n', cfn_matrix)\n",
    "\n",
    "tnr = cfn_matrix[0,0]/(cfn_matrix[0,0] + cfn_matrix[0,1])\n",
    "fpr = cfn_matrix[0,1]/(cfn_matrix[0,0] + cfn_matrix[0,1])\n",
    "fnr = cfn_matrix[1,0]/(cfn_matrix[1,0] + cfn_matrix[1,1])\n",
    "tpr = cfn_matrix[1,1]/(cfn_matrix[1,0] + cfn_matrix[1,1])\n",
    "acc = (cfn_matrix[0,0] + cfn_matrix[1,1])/cfn_matrix.sum()\n",
    "bac = (tnr + tpr)/2\n",
    "\n",
    "print('\\n' f\"True negative rate: {tnr: >6.2%}\")\n",
    "print(f\"False positive rate: {fpr: >6.2%}\")\n",
    "print(f\"False negative rate: {fnr: >6.2%}\")\n",
    "print(f\"True positive rate: {tpr: >6.2%}\")\n",
    "print(f\"Accuracy: {acc: >6.2%}\")\n",
    "print(f\"Balanced accuracy: {bac: >6.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 words by importance\n",
    "feature_imp = abs(logreg_model[1].coef_[0])\n",
    "feature_names = logreg_model[0].get_feature_names_out()\n",
    "\n",
    "imp_df = pd.DataFrame({'words': feature_names, 'coef': feature_imp})\n",
    "imp_df.sort_values(by='coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing y_test and y_pred\n",
    "comparison = pd.DataFrame({'Review': X_test, 'y_test':y_test, 'y_pred':y_pred})\n",
    "comparison['is_Correct'] = comparison['y_test'] == comparison['y_pred']\n",
    "\n",
    "comparison.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 mistakes made by prediction\n",
    "wrong_pred = comparison.loc[comparison['is_Correct'] != True]\n",
    "\n",
    "wrong_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coment√°rios e discuss√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Principais pontos aprendidos:\n",
    "- Aproveitei os passos iniciais para criar uma classe de limpeza do dataset, para relembrar esses conceitos que as vezes n√£o exercitamos;\n",
    "- Primeira vez criando uma WordCloud (tentei fazer com o formato do logo do Spotify mas n√£o sei se deu muito certo);\n",
    "- Utiliza√ß√£o do CountVectorizer pela primeira vez;\n",
    "- Utiliza√ß√£o de pipelines em conjunto com o gridsearch e acur√°cia balanceada;\n",
    "- N√£o sabia se na parte de maiores coment√°rios o trabalho se referia com rela√ß√£o ao n√∫mero de palavras ou caracteres do coment√°rios;\n",
    "- Aqui vai um agradecimento ao Nicolas, que sempre ajuda bastante nas d√∫vidas e √© bem prestativo.\n",
    "\n",
    "b) Principais limita√ß√µes na abordagem utilizada:\n",
    "- Preprocessamento dos Reviews poderia ser mais elaborado (como na fun√ß√£o que deixei exposta no notebook), utilizando mais t√©cnicas de NLP, fazendo com que as predi√ß√µes fossem mais adequadas;\n",
    "- O modelo, devido tamb√©m ao preprocessamento, aparenta estar muito sujeito a overfitting dependendo do modelo que utilizamos e de como otimizamos os hiperpar√¢metros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37083a178839ddb6837eca99e3841ef7be6dad5dc50c6d19829e2187d61ddd5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
